{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5056d64c",
   "metadata": {},
   "source": [
    "\n",
    "# ü§ñ JARVIS: Free Modular Voice Assistant (v1)\n",
    "This notebook is your **starting point for building a personal AI assistant (JARVIS)** with:\n",
    "- üß† **Free HuggingFace LLMs** (e.g. FLAN-T5)\n",
    "- üéô **Speech recognition**\n",
    "- üîä **Text-to-speech**\n",
    "- üí∏ **GPT-4 cost estimator** (for future planning)\n",
    "- üîå **Pluggable LLM interface** for easy upgrades\n",
    "\n",
    "**Say \"exit\" to stop the loop.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f67ee56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ‚úÖ Install dependencies\n",
    "!pip install -q transformers gtts speechrecognition pydub accelerate\n",
    "!apt-get install -y ffmpeg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6197fbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import torch\n",
    "import time\n",
    "import speech_recognition as sr\n",
    "from gtts import gTTS\n",
    "from pydub import AudioSegment\n",
    "from transformers import pipeline\n",
    "\n",
    "# ‚úÖ Modular LanguageModel (can be swapped later)\n",
    "class LanguageModel:\n",
    "    def __init__(self, model_name=\"google/flan-t5-base\"):\n",
    "        self.generator = pipeline(\"text2text-generation\", model=model_name, device=0 if torch.cuda.is_available() else -1)\n",
    "\n",
    "    def generate(self, prompt):\n",
    "        response = self.generator(prompt, max_new_tokens=100)[0]['generated_text']\n",
    "        return response\n",
    "\n",
    "# ‚úÖ Cost Estimator for GPT-4 (approx, in INR)\n",
    "def estimate_cost(prompt, response, model_name=\"gpt-4\"):\n",
    "    input_tokens = len(prompt.split()) * 1.3\n",
    "    output_tokens = len(response.split()) * 1.3\n",
    "    if model_name == \"gpt-4\":\n",
    "        cost = (input_tokens / 1000 * 0.01) + (output_tokens / 1000 * 0.03)\n",
    "        return round(cost * 85, 2)  # USD to INR\n",
    "    return 0.0\n",
    "\n",
    "# ‚úÖ Text-to-Speech\n",
    "def speak(text):\n",
    "    tts = gTTS(text=text, lang='en')\n",
    "    tts.save(\"response.mp3\")\n",
    "    sound = AudioSegment.from_file(\"response.mp3\", format=\"mp3\")\n",
    "    sound.export(\"response.wav\", format=\"wav\")\n",
    "    os.system(\"ffplay -nodisp -autoexit response.wav\")\n",
    "\n",
    "# ‚úÖ Speech-to-Text from Microphone\n",
    "def listen():\n",
    "    r = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"üé§ Speak now...\")\n",
    "        audio = r.listen(source)\n",
    "        try:\n",
    "            text = r.recognize_google(audio)\n",
    "            print(f\"üó£Ô∏è You said: {text}\")\n",
    "            return text\n",
    "        except sr.UnknownValueError:\n",
    "            return \"Sorry, I couldn't understand that.\"\n",
    "        except sr.RequestError:\n",
    "            return \"Speech recognition failed.\"\n",
    "\n",
    "# ‚úÖ Run Assistant Loop\n",
    "model = LanguageModel()  # Plug-and-play here\n",
    "while True:\n",
    "    prompt = listen()\n",
    "    if prompt.lower() in [\"exit\", \"quit\", \"stop\"]:\n",
    "        print(\"üëã Exiting JARVIS.\")\n",
    "        break\n",
    "\n",
    "    response = model.generate(prompt)\n",
    "    print(f\"ü§ñ JARVIS: {response}\")\n",
    "    speak(response)\n",
    "    print(f\"üí∏ Estimated GPT-4 cost (INR): ‚Çπ{estimate_cost(prompt, response)}\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
