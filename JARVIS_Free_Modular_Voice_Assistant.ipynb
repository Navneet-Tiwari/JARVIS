
# üìå JARVIS (Free Modular Version) - Voice Assistant Base

# ‚úÖ Setup: Install Required Libraries
!pip install -q transformers gtts speechrecognition pydub accelerate
!apt-get install -y ffmpeg

# ‚úÖ Imports
import os
import torch
import time
import speech_recognition as sr
from gtts import gTTS
from pydub import AudioSegment
from transformers import pipeline

# ‚úÖ Language Model Interface (Modular)
class LanguageModel:
    def __init__(self, model_name="google/flan-t5-base"):
        self.generator = pipeline("text2text-generation", model=model_name, device=0 if torch.cuda.is_available() else -1)

    def generate(self, prompt):
        response = self.generator(prompt, max_new_tokens=100)[0]['generated_text']
        return response

# ‚úÖ Cost Estimator (Future GPT-4 API)
def estimate_cost(prompt, response, model_name="gpt-4"):
    input_tokens = len(prompt.split()) * 1.3  # Rough approximation
    output_tokens = len(response.split()) * 1.3

    if model_name == "gpt-4":
        cost = (input_tokens / 1000 * 0.01) + (output_tokens / 1000 * 0.03)
        return round(cost * 85, 2)  # Approx INR conversion
    return 0.0

# ‚úÖ Text-to-Speech Output (gTTS)
def speak(text):
    tts = gTTS(text=text, lang='en')
    tts.save("response.mp3")
    sound = AudioSegment.from_file("response.mp3", format="mp3")
    sound.export("response.wav", format="wav")
    os.system("ffplay -nodisp -autoexit response.wav")

# ‚úÖ Speech-to-Text Input (Using Microphone)
def listen():
    r = sr.Recognizer()
    with sr.Microphone() as source:
        print("üé§ Speak now...")
        audio = r.listen(source)
        try:
            text = r.recognize_google(audio)
            print(f"üó£Ô∏è You said: {text}")
            return text
        except sr.UnknownValueError:
            return "Sorry, I couldn't understand that."
        except sr.RequestError:
            return "Speech recognition failed."

# ‚úÖ Main Assistant Loop (Run Continuously)
model = LanguageModel()  # Switch model here easily
while True:
    prompt = listen()
    if prompt.lower() in ["exit", "quit", "stop"]:
        print("üëã Exiting JARVIS.")
        break

    response = model.generate(prompt)
    print(f"ü§ñ JARVIS: {response}")
    speak(response)
    print(f"üí∏ Estimated GPT-4 cost (INR): ‚Çπ{estimate_cost(prompt, response)}")
